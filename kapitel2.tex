
\chapter{Sozial interagierende Roboter}
\label{sec:besondereroboter}
Im folgenden wird sich lediglich mit sozial interagierenden Robotern in der Altenpflege beschäftigt. Für Janowski unterscheiden sich sozial interagierende Roboter von Servicerobotern dahingehend, dass diese während der Ausführungen von Diensten Verhaltensweisen nachahmen, welche an die zwischenmenschliche Kommunikation angelehnt sind \cite[65]{vier}. Da dieser Bereich der Robotik relativ unerforscht ist, gibt es nur wenig Erfahrung mit dem Einsatz von Pflegerobotern in der Altenpflege. Sind keine politischen Vordefinitionen darüber, wie eine Technologie eingesetzt werden soll, vorhanden, mangelt es oftmals an einer konzeptuellen Herangehensweise \cite[1]{comEthics}. Verschiedene Veröffentlichungen beschäftigen sich in den letzten Jahren mit der Frage, inwiefern der Einsatz von Robotik in der Pflege ethisch vertretbar ist. Haker \cite[56]{haker} nennt drei Bereiche, in denen neue Technologien hilfreich sein können und neuerdings erprobt werden: die Pflegeassistenz, das Monitoring sowie die soziale Förderung. In diesem noch recht frühen Stadium des Einsatzes von Robotern in der Pflege besteht die Gefahr, dass ethische Grundsätze nicht in dem Designprozess berücksichtigt werden. Dass diese Grundsätze nicht definiert sind, stellt einen gesellschaftliches Problem dar.
\section{Vom Design implizierte Werte}
\label{sec:values}
Moore schreibt: \glqq On my view, computer ethics is the analysis of the nature and social impact of computer technology and the corresponding formulation and justification of policies for the ethical use of such technology\grqq \cite[1]{comEthics}. Eine Analyse der Wechselwirkungen zwischen Technologie und sozialen Konstrukten ist Voraussetzung dafür,  ein ethisch durchdachtes Computersystem zu designen. Nissenbaum setzt sich hierbei mit der Frage auseinander, inwiefern \textit{values in design}, also die durch das jeweilige Design implizierten Werte, besser in technischen und naturwissenschaftlichen Bereichen reflektiert und integriert werden können \cite{nissenbaum}. Oftmals gibt es in diesen universitären Fakultäten wenig Überschneidungen mit den Sozial- und Geisteswissenschaften, welche eine längere Tradition der Methodologie aufweisen [ebd.: lxvi]. Sie schlägt vor, dass pflichtbewusste Designer*Innen ihre values in design auf drei Wissensebenen reflektieren. Zuerst werden diese hinsichtlich des Wissensstandes in Technik und Naturwissenschaft überprüft, folgend durch eine philosophische Reflexion, und zuletzt durch eine empirische Überprüfung im Anwendungsfeld [ebd.]. Durchgängig sollte dabei im Fokus stehen, dass sich alle drei Bereiche durchdringen und gegenseitig beeinflussen. Diese sollten also, während der Fokus sich in einem dieser Bereiche befindet, kontinuierlich mitgedacht werden. Während  im ersten Schritt sämtliche im jeweiligen technischen Feld vorhandenen Werte auf den Prüfstand gestellt werden, um sich sinnvoll für ein Design zu entscheiden, wird im zweiten Schritt geschaut, wo welche Werte ihren Ursprung haben, welche Relevanzen und Bedeutungen ihnen innewohnen und wie sie normativ beeinflusst sind [ebd.: lxvii]. Werte können eine moralische, eine politische und eine soziale Konnotation haben [ebd.]. Werden Werte ins Design bewusst integriert, sollte im nächsten Schritt überprüft werden, ob ihre Einverleibung geglückt ist, also ob die Intentionen der*s Designer*In sich erfüllen [ebd.: lxviii]. Möglich ist, ein partizipatives Design zu erstellen, wo die Entwicklungsschritte einer Technologie oder einer Maschine jeweils an eine Überprüfung auf ihre Wirksamkeit im späteren Anwendungsbereich rückgekoppelt sind [ebd.]. Nissenbaum hat mit Kolleg*Innen hierfür eine eigene Methode entwickelt, in der  vier Schritte durchlaufen werden \cite{nissenbaum}. Zunächst wird die Entdeckung der jeweils zugrunde liegenden Werte angestrebt, folgend wird die Übersetzung in das jeweilige Feld vorgenommen, danach werden zumeist auftretender Konflikte oder Inkontinenzen gelöst und zuletzt wird eine erfolgreichen Einverleibung überprüft [ebd.: lxix]. Der Einsatz von Robotern in der Pflege allgemein, aber auch für die soziale Interaktion, birgt viele Möglichkeiten, über eine reflektierte Herangehensweise bezüglich der values in design, die ethischen Vorraussetzungen positiv zu beeinflussen. Sowohl Sharkey und Sharkey als auch Kehl stellen fest, dass es hier einer genauen Überprüfung der Grundvorraussetzungen und eine Zusammenarbeit mit den Pflegebedürftigen bedarf \cite{sharky}\cite{kehl}. Mithilfe empirischer Untersuchungen und partizipativer Technikgestaltung wäre es möglich, wichtige Werte von Älteren herauszufinden und aufzugreifen und somit auf technischer Seite dafür zu sorgen, dass ethische Fragen in das Design eingearbeitet werden.

\section{Kann Täuschung ethisch Vertretbar sein?}
\label{sec:täuschung}
Auch Sharkey und Sharkey sehen als wichtige Bereiche, in denen Roboter eingesetzt werden können, die Unterstützung der Älteren, sowie der sie Pflegenden; das Monitoring von Verhalten und Gesundheitszustand; sowie das Gesellschaftleisten \cite[21]{sharky}. Menschen können durch Roboter emotional stimuliert werden und diese können dabei helfen \glqq Gefühle wie Traurigkeit, Zorn und Einsamkeit zu regulieren\grqq \cite[58]{haker}. Was die ethischen Konsequenzen angeht, stimmen die meisten Veröffentlichungen hinsichtlich der sich ergebenen Problematiken überein, erkennen jedoch auch den Nutzen an. An dieser Stelle wird sich auf eine Analyse der sozialen Unterstützung durch Roboter beschränkt. Haker stellt drei Modelle vor, in denen sie die unterschiedlichen Argumentationslinien bezüglich der Position von Robotern in sozialen Beziehungen im Pflegebereich darlegt [ebd.: 59 ff]. Im \textit{Ausschlussmodell} wird angenommen, dass zwischen Menschen und Robotern keine gleichwertige Beziehung existieren kann. Roboter werden als zu sozialer Interaktion nicht fähig gesehen, problematisch sei es, wenn Pflegebedürftige dieses durch kognitive Einschränkungen nicht mehr nachvollziehen können. \glqq [. . . ] So warnen Kritiker nicht nur vor der Infantilisierung der Klienten, die durch die BetreuerInnen oder Angehörigen erfolgen könnte, sondern zugleich besteht auch die Gefahr der Objektivierung, indem letztlich nämlich mit den Bedürfnissen älterer Menschen gespielt werde. Die absichtliche Simulation reziproker Interaktion durch Dritte ist von einer anderen Kategorie als die selbstbestimmte Entscheidung älterer Menschen, Roboter als soziales Spielzeug in ihr Leben einzubeziehen.\grqq [ebd.: 60]. Im \textit{Ergänzungsmodell} werden Roboter vor allem für gewisse Arbeiten gedacht, die durch eine Ergänzung der Pflegeleistung diese unterstützen. Dabei wird der Einsatz von Robotern immer durch das Pflegepersonal betreut, \glqq [. . . ] ihr Einsatz ist klar durch den therapeutischen Rahmen gegeben, den weder die Klienten (bzw. Patienten) noch die Roboter durchbrechen können oder sollen.\grqq [ebd.: 61]. Haker wirft die Frage auf, ob in dieser Argumentationslinie das autonome Handlungsvermögen von Robotern nicht unterschätzt wird. Im \textit{Kompensationsmodell} geht es darum durch den Einsatz von Robotern die Abwesenheit anderer Interaktion zu kompensieren. Wenn soziale Interaktion mit Angehörigen oder Pflegepersonal zeitlich nicht möglich ist, sei es immer noch besser wenn Roboter den zu Pflegenden ein Wohlgefühl vermitteln und ihnen Gesellschaft leisten würden. Die Argumentationslinie des Kompensationsmodells bewertet das Steigern des Wohlbefindens als zentral. Es nimmt in Kauf, dass die zu Pflegenden bezüglich der Reziprozität der Beziehung getäuscht werden, falls sie kognitiv nicht mehr feststellen können, dass sie gerade mit einem Roboter interagieren [ebd.: 62]. Je nachdem, welcher Argumentationslinie gefolgt wird, wird die Annahme vertreten, dass soziale Beziehungen zu Robotern niemals gleichwertig sein können, was im schlimmsten Fall von Älteren oder Demenzkranken nicht gemerkt wird, womit sie also getäuscht werden. Oder der Einsatz von Robotern wird dennoch als positiv bewertet, da anderweitige soziale Interaktion bewusst ergänzt werden kann, oder im schlechteren Fall die Abwesenheit sozialer Interaktion durch diese andere Form der Interaktion kompensiert. Sparrow und Sparrow lehnen den Einsatz von Robotern nicht grundsätzlich ab, befinden ethische Bedenken jedoch als zentral. Sie weisen darauf hin, wie kompliziert die einzelnen Aufgaben im Bereich der Pflege sind, und bezweifeln, dass künstliche Intelligenz in naher Zukunft solch komplexe und verantwortungsvolle Aufgaben übernehmen werden kann \cite[145 ff]{sparrow}. Sie gehen davon aus, dass das zentrale menschliche Bedürfnis, geliebt zu sein und umsorgt zu werden, von Robotern nur befriedigt werden kann, wenn man der Täuschung unterliegt, dass diese gleichwertige gefühlvolle Kreaturen sind [ebd.: 154 ff]. Beim Empfinden positiver Emotionen ist die Beziehung zwischen zwei Lebewesen zentral. Sie ist dadurch charakterisiert, dass auch ein Gegenüber Bedürfnisse und Erwartungen hat, und dass gegenseitige Forderungen die Beziehung formen, welche sowohl unvorhersehbar, als auch manchmal anmaßend und unerwartet sein können [ebd.: 149]. \glqq For robots to be capable even of imitating these responses successfully they would need to possess physical bodies capable of the same level of expressiveness and individuality as human bodies. Moreover, entities which do not understand the facts about human experience and mortality that make tears appropriate will be unable to fulfil this caring role \grqq [ebd.: 154 ff]. Die Täuschung, sich von einem Roboter umsorgt und geliebt zu fühlen, ist vor allem problematisch, da Illusionen wirkliche Bedürfnisse nicht dauerhaft befriedigen, wirkliche Interessen nicht dauerhaft bedienen und auch ein Wohlgefühl nicht dauerhaft illusionär, oder durch Selbsttäuschung, aufrechterhalten werden kann [ebd.: 155]. Menschen wollen nicht in illusionärer Annahme glauben, dass sie von illusionären technischen Maschinen geliebt und umsorgt werden, sondern sie haben das reale Bedürfnis von Menschen geliebt und umsorgt zu werden [ebd.]. \glqq Insofar as robots can make people happier only when they are deceived about the robots’ real nature, robots do not offer real improvements to people’s well-being; in fact the use of robots can be properly said to harm them.\grqq[ebd.]. Auch Haker stellt diesbezüglich fest: \glqq Ohne diese Form der imaginativen Personalisierung des Roboters verlöre das Spiel mit ihm schnell seinen Reiz – oder umgekehrt: es wäre nicht mehr klar, was der Unterschied beispielsweise zu Stofftieren wäre, mit denen ältere Menschen genauso imaginativ soziale Interaktionen aufbauen könnten \grqq \cite[59]{haker}. Sparrow und Sparrow vermuten, dass positive emotionale Effekte, die aus der Interaktion mit Robotern hervorgehen, sich nicht über einen langen Zeitraum halten lassen, da eine authentische Beziehung nicht aufgebaut werden kann \cite[149]{sparrow}. Diese Effekte beruhen somit bloß auf der Faszination einer neuen, anregenden Erfahrung. Sharkey und Sharkey beantworten die Frage, ob ein Roboter für Ältere ein*e Gefährt*In darstellen kann, mit der Festellung, dass einsame Menschen von der Anwesenheit eines Roboters profitieren können, aber sicherlich um einiges mehr profitieren würden, wenn sie sich in einem freundlichen sozialen Umfeld befänden \cite[34]{sharky}. Roboter könnten jedoch als Gefährten nicht einfach aufgrund der stattfindenden Täuschung als unethisch gewertet werden. Es sei Älteren zuzutrauen durchaus bewusst zu entscheiden, die Interaktion mit Robotern zu genießen, auch wenn es sich um eine illusionäre Beziehung handelt [ebd.: 36]. Auch von einer Infantilisierung könne nicht in jedem Fall gesprochen werden, es gäbe durchaus Situationen wo ein älterer Mensch sich entscheidet einfach die Möglichkeit zu nutzen und das Beste daraus zu machen. Das Aussehen von Robotern ist eine weitere wichtige Frage, werden diese eher dem Aussehen von Lebewesen nachempfunden, oder wird ein abstraktes Äußeres bevorzugt (vgl. \ref{sec:values}). Je abstrakter die Erscheinung eines Roboters ausfällt, desto eher lässt sich vermuten, dass Pflegebedürftiger einer Täuschung weniger schnell unterliegen. Es wäre möglich den Roboter so zu kreieren, dass einer Vereinsamung von Pflegebedürftigen durch Warnmechanismen entgegengewirkt wird. Die zentrale Frage ist, ob Roboter im Hinblick darauf entwickelt werden, um Pflegebedürftigen zu helfen, oder im Hinblick darauf, Kosten im Pflegebereich einzusparen und das Arbeitspensum des Pflegepersonals zu reduzieren [ebd.: 30].
\chapter{Bedenken}
Als Gründe für die Entwicklung von Robotern in der Pflege führt Haker den demografischen Wandel in vielen Industrienationen, den Pflegenotstand, die Beförderung von Unabhängigkeit in der häuslichen Pflege durch Monitoring und Überwachung, sowie die Kostenreduzierung an \cite[56]{haker}. Dies geschieht, auch wenn noch nicht alle ethischen Fragen der Täuschung geklärt sind. Es scheint also unabdingbar, dass Roboter im Pflegebereich verstärkt zum Einsatz kommen werden. Dies geschieht, auch, wenn noch nicht alle ethischen Fragen bezüglich der Täuschung von sozial interagierenden Robotern geklärt sind. Interessant ist hierbei wie sich dies auf die Privatsphäre und das generelle Wohlbefinden auswirkt.
\section{Angriff auf die Privatsphäre?}
\label{sec:priv}
In der Literatur wird disskutiert, wie eine Kameraüberwachung in das Aussehen und Auftreten von Robotern integriert werden kann oder unter welchen Voraussetzungen Räume der Privatsphäre wie Bad und Schlafzimmer von Robotern betreten werden dürfen. Denn erst durch die Schaffung eines privaten Raumes kann es zu der Ausübung von Autonomie kommen \cite[178]{priv}. Dem Raum wird seine Privatsphäre genommen, sobald eine dauerhafte Kameraüberwachung installiert wird. Somit ist fraglich, ob z. B. aufzeichnende Assistenzsysteme in Privathaushalten wirklich die Autonomie fördern. Desweiteren geht Grimm darauf ein, dass vier Funktionen für die Gewährleistung von Privatheit erfüllt sein müssen: 1. Persönliche Autonomie, 2. Emotionale Entspannung, 3. Selbsteinschätzung, 4. Eingeschränkte und geschützte Kommunikation [ebd.: 178]. Die Einführung eines Roboters, der immer zu erreichbar ist, fördert zwar die persönliche Autonomie, verletzt jedoch die Möglichkeit der eingeschränkten und geschützten Kommunikation.
Darüber hinaus werden bei jeder Interaktion Daten erzeugt, was eine Menge Fragen mit sich bringt: Wem gehören die Daten? Sollten sie gespeichert werden und wenn ist zu klären wo. Dürfen die Daten weiter verarbeitet werden? Dazu sagt Sullins: \grqq In one sense this could be immensely powerful data that could lead to much healthier lifestyle choices. But it could also be a serious breach in privacy if the information got into the wrong hands which would be easily accomplished since third parties have access to information collected on smartphones and online applications.\grqq \cite{sullins}.
\section{Hürden bei der Interaktion}
\label{sec.interaction}
Sharkey und Sharkey untersuchen den Einsatz von Robotern in der Pflege vor allem unter dem Kriterium des Wohlergehens älterer pflegebedürftiger Menschen \cite[28]{sharky}. In Bezug auf die unterstützende- oder Pflegeassistenz sehen sie die Gefahr, dass durch diese sich der menschliche Kontakt in ihrem Alltag reduziert, weil einfache Tätigkeiten wie Anreichen oder Putzen, die auch ohne Pflegekraft ausgeführt werden können, von Robotern übernommen werden [ebd.: 29]. Hier kann es passieren, dass die Älteren das Gefühl einer Verobjektivierung erfahren, sowie dass sie die Kontrolle über ihr Leben verlieren. Die Abnahme sozialer Interaktion im Alltag führt oftmals zu einer Zunahme des Stressempfindens und zur Verringerung kognitiver Fähigkeiten, allgemein zeichnet sie sich durch eine Verschlechterung des psychischen und körperlichen Gesundheit aus [ebd.: 29/30]. Pflegebedürftigen durch das Einführen von Robotern in der Pflege zusätzlich sozialer Interaktion zu entziehen bewerten Sharkey und Sharkey als ethisch nicht vertretbar, wobei sie anmerken, dass Roboter im besten Fall durch Interaktion ihrerseits den Mangel kompensieren [ebd.: 30]. Dieses bedarf weiterer Untersuchungen.
\section{Gefahren von verfrühtem Einsatz}
\label{sec:gefahren}
Wenn die Anwendung von Robotern sich als wirtschaftlich erfolgreich herausstellt, besteht die Gefahr, dass sich ihr Einsatz trotz ethischer Unzulänglichkeiten durchsetzt. Gründe dafür können die bereits genannten demografischen Entwicklungen in Industrienationen wie auch die mangelhaften Beschäftigungszahlen im Pflegebereich sein \cite[28 ff]{sharky}. Problematisch ist, dass der Einsatz von Robotern im Gesundheitsbereich die Bereitstellung von weiteren Mitteln zur Weiterentwicklung und Erforschung neuer Technologien rechtfertigt \cite[57]{haker}. Haker bemerkt hierzu, dass wenn die Technologien nunmal vorhanden sind, sie dementsprechend auch auf diesen neuen Bereich angewandt werden [ebd.]. Bevor überhaupt ethische Kriterien und Regeln für den Einsatz von Robotern diskutiert und festgelegt werden, wird ihr Einsatz bereits vorangetrieben, da der Stand der Technologie diesen hergibt. Es existiert weltweit im Bereich der Technologieforschung und -entwicklung ein großes Interesse, Roboter kontinuierlich weiterzuentwickeln und im Bereich der Anwendung zu Erproben. Zudem stellt sich die Frage, wer darüber entscheidet, wie die Roboter agieren und wie sie designed (\ref{sec:values}) sind. \glqq In Feldern wie der Pflegerobotik, die sich noch in einem sehr frühen Stadium der Entwicklung befinden und deren Anwendungsmöglichkeiten sich folglich erst unscharf abzeichnen, ist diese […] folgenorientierte Herangehensweise mit grundlegenden Problemen konfrontiert – schließlich liegen die Technikfolgen noch weitgehend im Dunkeln, womit auch deren ethische Beurteilung weitgehend ins Leere läuft.\grqq \cite[148]{kehl}.
\section{Mögliche Lösungsstrategien}
\label{sec:lösung}
In ihrem Fazit bezieht Haker drei unterschiedliche ethische Rahmentheorien mit ein, um mithilfe dieser und der zuvor in \ref{sec:täuschung} genannten Argumentationslinien Regeln für den Einsatz von Robotern in der Pflege zu erarbeiten \cite[59]{haker}: 1. Jedem Menschen steht es frei, sich einen \glqq sozialen Roboter \grqq zuzulegen., 2. Der spontanen reziproken Interaktionen ist Vorzug zu geben, ein Roboter ist nur Zusatz., 3. Ein infantilisierender Einsatz von Robotern ist auszuschließen., 4. Sofern Roboter Handlungen ausführen, die bestimmte Reaktionen hervorrufen, ist die Intimität und Integrität der Personen zu gewährleisten., 5. Roboter können unter Umständen ein Sicherheitsrisiko darstellen. Die Verantwortung für ihren Einsatz ist zu klären [ebd.: 65/66]. Eine Ethik, die sich auf die Rahmentheorie der Menschenrechte stützt, muss klären, wie sich der Einsatz von Robotern zum Recht auf Wohlergehen, auf Privatheit, auf Gewaltfreiheit und insgesamt auf den Schutz der persönlichen Integrität verhält [ebd.: 63/64]. Innerhalb einer solchen Ethik stellt sich grundsätzlich die Frage, ob der Einsatz von Robotern nicht die Würde älterer Menschen verletzt. Wird im Sinne eine Befähigungsethik im Hinblick auf die Steigerung des Wohlbefindens argumentiert, ist zu überprüfen \glqq unter welchen Bedingungen Roboter Menschen nicht nur stimulieren, sondern tatsächlich in ihren Fähigkeiten fördern und zu mehr Freiheit ermächtigen \grqq [ebd.: 64]. Auch eine utilitaristische ethische Ausrichtung betrachtet eine Steigerung des Wohlbefindens \cite[8]{mill} und somit die Effekte der Interaktion zwischen Mensch und Roboter. Mill schreibt: \glqq [...] ethics has been not so much a guide to men in forming their moral views as a consecration of the views they actually have; but men’s views—both for and against—are greatly influenced by what effects on their happiness they suppose things to have; \grqq \cite[2]{mill}. Ein utilitaristischer Ethikansatz würde argumentativ so weit gehen, dass die positiven Effekte wichtiger sind, als die menschliche Würde, sollten Menschen nicht mehr in der Lage sein eine Verletzung ihrer Würde zu reflektieren \cite[64]{haker}. Kehl spricht sich für eine umfassende Auseinandersetzung mit der Frage aus, inwiefern der Einsatz von Robotik in der Pflege sinnvoll sein kann \cite[143 ff]{kehl}. \glqq Für die Pflegerobotik erscheint dies besonders drängend, da man es hierbei mit einer Technologie zu tun hat, die aufgrund ihrer Interaktivität und zunehmenden Autonomiefähigkeit ganz neue technische Möglichkeiten bietet, die aber gerade nicht Selbstzweck sein dürfen, sondern die es sinnvoll – und zwar im Sinne guter Pflege – nutzbar zu machen gilt \grqq [ebd.: 144]. Als Instrument schlägt er die Bedürfnis- und Bedarfsanalyse vor. Sowohl was das Thema Privatsphäre angeht, als auch values in design, sei es notwendig bei der Entwicklung neuer Technologien in einen kontinuierlichen Austausch mit denjenigen zu treten, die vom Einsatz dieser Technologien letztlich betroffen sind [ebd.].
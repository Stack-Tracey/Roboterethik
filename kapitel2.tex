\chapter{Ethische Erläuterungen zu Robotik in der Pflege}
\label{ch:2}
 Als Gründe für die Entwicklung von Robotern in der Pflege führt sie den demographischen Wandel in vielen Industrienationen, den Pflegenotstand, die Beförderung von Unabhängigkeit in der häuslichen Pflege durch Monitoring und Überwachung, sowie die Kostenreduzierung an \cite[56]{haker}.  Dabei beherbergt gerade die Entwicklung von Pflegerobotern noch viele ungeklärte ethische Hürden. Im folgenden wird sich lediglich mit sozial interagierenden Robotern in der Altenpflege  beschäftigt. Für Janowski unterscheiden sich sozial  interagierende  Roboter  von  reinen  Service-robotern  dadurch,  dass  sie  während  der  Ausführung  von  Diensten  Verhaltensweisen  emulieren,  die  an  der zwischenmenschlichen  Kommunikation  orientiert  sind. \cite[65]{vier}
Da dieser Bereich der Robotik noch vergleichsweise in den Kinderschuhen steckt, gibt es nur wenig Erfahrung mit dem Einsatz von Pflegerobotern und wo ein politisches Vakuum darüber herrscht, wie Computertechnologie eingesetzt werden sollte, herrscht häufig auch ein konzeptuelles \cite[1]{comEthics}.  Verschiedene Veröffentlichungen beschäftigen sich in den letzten Jahren mit der Frage, inwiefern der Einsatz von Robotik in der Pflege ethisch vertretbar ist. Haker \cite[56]{haker} nennt drei Bereiche, in denen neue Technologien hilfreich sein können und neuerdings erprobt werden: die Pflegeassistenz, das Monitoring sowie die soziale Förderung.



\section{Beziehung zwischen Design und Werten von Technologie}
\label{sec:values}
Es ist wichtig, frühzeitig ethische Probleme während des Designprozesses zu bedenken.
Dabei sagt Moore: "On my view, computer ethics is the analysis of the nature and social impact of computer technology and the corresponding formulation and justification of policies for the ethical use of such technology" \cite[1]{comEthics}. Eine Analyse der Wechselwirkungen zwischen Technologie und sozialen Konstrukten ist demnach unabdingbar, wenn man ein ethisch korrektes Computersystem designen möchte. Nissenbaum setzt sich hierbei mit der Frage auseinander, inwiefern \textit{values in design}, also die durch das jeweilige Design implizierten Werte, besser in technischen und naturwissenschaftlichen Bereichen reflektiert und integriert werden können \cite{nissenbaum}. Oftmals gibt es in diesen universitären Fakultäten wenig Überschneidungen mit den Sozial- und Geisteswissenschaften, welche eine längere Tradition der Methodologie aufweisen [ebd.: lxvi]. Sie schlägt vor, dass pflichtbewusste Designer*Innen ihre values in design auf drei Wissensebenen reflektieren. Zuerst werden diese hinsichtlich des Wissensstandes in Technik und Naturwissenschaft überprüft, folgend durch eine philosophische Reflexion, und zuletzt durch eine empirische Überprüfung im Anwendungsfeld [ebd.]. Durchgängig sollte dabei im Fokus stehen, dass sich alle drei Bereiche durchdringen und gegenseitig beeinflussen. Sie sollten also, während der Fokus sich in einem dieser Bereiche befindet, kontinuierlich mitgedacht werden. Während also im ersten Schritt sämtliche im jeweiligen technischen Feld vorhandenen Werte auf den Prüfstand gestellt werden um sich sinnvoll für ein Design zu entscheiden, wird im zweiten Schritt geschaut, wo Werte ihren Ursprung haben, welche Relevanzen und Bedeutungen ihnen innewohnen und wie sie normativ beeinflusst sind [ebd.: lxvii]. Werte können eine moralische, eine politische und eine soziale Konnotation haben [ebd.]. Werden Werte ins Design bewusst integriert, sollte im nächsten Schritt überprüft werden, ob ihre Einverleibung geglückt ist, also ob die Intentionen der*s Designer*In sich erfüllen [ebd.; lxviii].  Möglich ist, ein partizipatives Design zu erstellen, wo die Entwicklungsschritte einer Technologie oder einer Maschine jeweils rückgekoppelt sind an eine Überprüfung auf ihre Wirksamkeit im späteren Anwendungsbereich [ebd.]. Nissenbaum hat mit Kolleg*Innen hierfür eine eigene Methode entwickelt, in der hierfür vier Schritte durchlaufen werden \cite{nissenbaum}. Zunächst die Entdeckung der jeweils zugrunde liegenden Werte, folgend ihre Übersetzung in das jeweilige Feld, danach die Lösung zumeist auftretender Konflikte oder Inkontinenzen und zuletzt die Überprüfung einer erfolgreichen Einverleibung [ebd.: lxix]. Der Einsatz von Robotern in der Pflege allgemein, aber auch in Bezug auf soziale Interaktion, birgt viele Möglichkeiten, über eine reflektierte Herangehensweise bezüglich der values in design, die ethischen Vorraussetzungen positiv zu beeinflussen. Wie Sharkey und Sharkey und Kehl feststellen, bedarf es hier einer genauen Überprüfung der Grundvorraussetzungen und eine Zusammenarbeit mit den Pflegebedürftigen \cite{sharky}\cite{kehl}. Mithilfe empirischer Untersuchungen und  partizipativer Technikgestaltung wäre es möglich, wichtige Werte von Älteren herauszufinden und aufzugreifen und somit auf technischer Seite dafür zu sorgen, dass ethische Fragen in das Design eingearbeitet werden. 

\section{Kann Täuschung ethisch Vertretbar sein?}
\label{sec:täuschung}
\\Auch Sharkey und Sharkey sehen als wichtige Bereiche, in denen Roboter eingesetzt werden können, die Unterstützung der Älteren, sowie der sie pflegenden; das Monitoring von Verhalten und Gesundheitszustand; sowie das Gesellschaftleisten \cite[ 27]{sharky}. Menschen können durch Roboter emotional stimuliert werden und diese können dabei helfen “Gefühle wie Traurigkeit, Zorn und Einsamkeit zu regulieren” \cite[58]{haker}. Was die ethischen Konsequenzen angeht, stimmen die meisten Veröffentlichungen hinsichtlich der sich ergebenen Problematiken überein, erkennen jedoch auch den Nutzen an. An dieser Stelle wird sich eine Analyse der sozialen Unterstützung durch Roboter beschränkt. Haker stellt drei Modelle vor, in denen sie die unterschiedlichen Argumentationslinien bezüglich der Position von Robotern in sozialen Beziehungen im Pflegebereich darlegt \cite[59 ff]{haker}. Im Ausschlussmodell wird angenommen, dass zwischen Menschen und Robotern keine gleichwertige Beziehung existieren kann. Roboter werden als zu sozialer Interaktion nicht fähig gesehen, problematisch sei es, wenn Pflegebedürftige dieses durch kognitive Einschränkungen nicht mehr nachvollziehen können. “[…]So warnen Kritiker nicht nur vor der Infantilisierung der Klienten, die durch die BetreuerInnen oder Angehörigen erfolgen könnte, sondern zugleich besteht auch die Gefahr der Objektivierung, indem letztlich nämlich mit den Bedürfnissen älterer Menschen gespielt werde. Die absichtliche Simulation reziproker Interaktion durch Dritte ist von einer anderen Kategorie als die selbstbestimmte Entscheidung älterer Menschen, Roboter als soziales Spielzeug in ihr Leben einzubeziehen” [ebd.: 60]. Im Ergänzungsmodell werden Roboter vor allem für gewisse Arbeiten gedacht, die durch eine Ergänzung der Pflegeleistung diese unterstützen. Dabei wird der Einsatz von Robotern immer durch das Pflegepersonal betreut, “[…]ihr Einsatz ist klar durch den therapeutischen Rahmen gegeben, den weder die Klienten (bzw. Patienten) noch die Roboter durchbrechen können oder sollen” [ebd.: 61]. Haker wirft die Frage auf, ob in dieser Argumentationslinie das autonome Handlungsvermögen von Robotern nich unterschätzt wird \cite{haker}.\\ Im Kompensationsmodell geht es darum durch den Einsatz von Robotern die Abwesenheit anderer Interaktion zu kompensieren. Wenn soziale Interaktion mit Angehörigen oder Pflegepersonal zeitlich nicht möglich ist, sei es immer noch besser wenn Roboter den zu Pflegenden ein Wohlgefühl vermitteln und ihnen Gesellschaft leisten würden. Die Argumentationslinie des Kompensationsmodells bewertet das Steigern des Wohlbefindens als wichtiger, selbst wenn die zu Pflegenden bezüglich der Reziprozität der Beziehung getäuscht werden würden, falls sie kognitiv nicht mehr feststellen können, dass sie gerade mit einem Roboter interagieren [ebd.: 62].\\ Je nach dem, welcher Argumentationslinie gefolgt wird, wird die Annahme vertreten, dass soziale Beziehungen zu Robotern niemals gleichwertig sein können, was im schlimmsten Fall von Älteren oder Demenzkranken nicht gemerkt wird, womit sie also getäuscht werden. Oder der Einsatz von Robotern wird dennoch als positiv bewertet, da anderweitige soziale Interaktion bewusst ergänzt werden kann, oder im schlechteren Fall die Abwesenheit sozialer Interaktion durch diese andere Form der Interaktion kompensiert.\\Sparrow und Sparrow lehnen den Einsatz von Robotern nicht grundsätzlich ab, befinden ethische Bedenken jedoch als zentral. Sie weisen darauf hin, wie kompliziert die einzelnen Aufgaben im Bereich der Pflege sind, und bezweifeln, dass künstliche Intelligenz in naher Zukunft solch komplexe und verantwortungsvolle Aufgaben übernehmen werden kann \cite[145 ff]{sparrow}. Sparrow und Sparrow gehen davon aus, dass das zentrale menschliche Bedürfnis, geliebt zu sein und umsorgt zu werden, von Robotern nur befriedigt werden kann, wenn man der Täuschung unterliegt, dass diese gleichwertige Kreaturen mit Gefühlen sind \cite[154 ff]{sparrow}. Beim Empfinden dieser positiven Emotionen ist die Beziehung zwischen zwei Lebewesen zentral. Sie ist dadurch charakterisiert, dass auch ein Gegenüber Bedürfnisse und Erwartungen hat, und dass gegenseitige Forderungen die Beziehung formen, welche sowohl unvorhersehbar, als auch manchmal anmaßend und unerwartet sein können [ebd.: 149]. “For robots to be capable even of imitating these responses successfully they would need to possess physical bodies capable of the same level of expressiveness and individuality as human bodies. Moreover, entities which do not understand the facts about human experience and mortality that make tears appropriate will be unable to fulfil this caring role” \cite[154]{sparrow}. Die Täuschung, sich von einem Roboter umsorgt und geliebt zu fühlen, ist vor allem problematisch, da Illusionen wirkliche Bedürfnisse nicht dauerhaft befriedigen, wirkliche Interessen nicht dauerhaft bedienen und auch ein Wohlgefühl nicht dauerhaft illusionär, oder durch Selbsttäuschung, aufrecht erhalten werden kann [ebd.:155]. Menschen wollen nicht in illusionärer Annahme glauben, dass sie von illusionären technischen Maschinen geliebt und umsorgt werden, sondern sie haben das reale Bedürfnis von Menschen geliebt und umsorgt zu werden [ebd.]. “Insofar as robots can make people happier only when they are deceived about the robots’ real nature, robots do not offer real improvements to people’s well-being; in fact the use of robots can be properly said to harm them“ [ebd.].  Auch Haker stellt diesbezüglich fest: “Ohne diese Form der imaginativen Personalisierung des Roboters verlöre das Spiel mit ihm schnell seinen Reiz – oder umgekehrt: es wäre nicht mehr klar, was der Unterschied beispielsweise zu Stofftieren wäre, mit denen ältere Menschen genauso imaginativ soziale Interaktionen aufbauen könnten“ \cite[59]{haker}. Sparrow und Sparrow vermuten, dass positive emotionale Effekte, die aus der Interaktion mit Robotern hervorgehen, sich nicht über einen langen Zeitraum halten lassen, da eine authentische Beziehung nicht aufgebaut werden kann \cite[149]{sparrow}. Diese Effekte beruhen somit bloß auf der Faszination einer neuen, anregenden Erfahrung. Sharkey und Sharkey beantworten die Frage, ob ein Roboter für Ältere ein*e Gefährt*In darstellen kann, mit der Festellung, dass einsame Menschen von der Anwesenheit eines Roboters profitieren können, aber sicherlich um einiges mehr profitieren würden, wenn sie sich in einem freundlichen sozialen Umfeld befänden \cite[34]{sharky}. Sie schreiben jedoch auch, dass Roboter als Gefährten nicht einfach aufgrund der stattfindenden Täuschung als umethisch gewertet werden können. Ältere könnten durchaus bewusst entscheiden, dass sie die Interaktion mit Robotern genießen, auch wenn es sich um eine illusionäre Beziehung handelt [ebd.: 36]. Auch von einer Infantilisierung kann nicht in jedem Fall gesprochen werden, es gibt durchaus Situationen wo ein älterer Mensch sich entscheidet einfach die Möglichkeit zu nutzen und das Beste daraus zu machen.
Das Aussehen von Robotern ist eine weitere wichtige Frage, werden diese eher dem Aussehen von Lebewesen nachempfunden, oder wird ein abstraktes Äußeres bevorzugt. Je abstrakter die Erscheinung eines Roboters ausfällt, desto eher lässt sich vermuten, dass Pflegebedürftiger einer Täuschung weniger schnell unterliegen. Es wäre möglich den Roboter so zu kreieren, dass einer Vereinsamung von Pflegebedürftigen durch Warnmechanismen entgegengewirkt wird. Werden diese im Hinblick darauf entwickelt, um Pflegebedürftigen zu helfen, oder im Hinblick darauf, Kosten im Pflegebereich einzusparen und das Arbeitspensum des Pflegepersonals zu reduzieren \cite[30]{sharky}.

\section{Probleme mit der Privatsphäre}
\label{sec:priv}
In der Literatur angesprochene Themen sind dabei, wie eine Kameraüberwachung in das Aussehen und Auftreten von Robotern integriert werden kann oder unter welchen Voraussetzungen gewisse private Räumen wie Bad und Schlafzimmer von Robotern betreten werden dürfen. Denn erst durch die Schaffung eines privaten Raumes, kann es zu der Ausübung von Autonomie kommen \cite[178]{priv}. Dieser wird aber beschnitten, sobald z.B dauerhafte Kameraüberwachung installiert wird. Somit ist fraglich, ob z.B aufzeichnende Assistenzsysteme in Privathaushalten wirklich die Autonomie fördern. Desweiteren gehen Grimm und Krah darauf ein, dass vier Funktionen für die Gewährleistung von Privatheit erfüllt sein müssen: 1. \textit{personal autonomy}, 2. \textit{emotional release}, 3. \textit{self-evaluation}, 4. \textit{limmited and protectet communication} [ebd.: 178]. Die Einführung eines Roboters der immer zu erreichbar ist, fördert zwar den ersten Punkt, verletzt jedoch den vierten.
Darüber hinaus werden bei jeder Interaktion Daten erzeugt, was eine Menge Fragen mit sich bringt: Wem gehören die Daten? Sollten sie gespeichert werden und wenn ist zu klären wo, Dürfen die Daten weiter verarbeitet werden? Dazu sagt Sullins: "In one sense this could be immensely powerful data that could lead to much healthier lifestyle choices. But it could also be a serious breach in privacy if the information got into the wrong hands which would be easily accomplished since third parties have access to information collected on smartphones and online applications." \cite{sullins}. 

\section{Bedenken bei der Einführung von Robotern}
Sharkey und Sharkey untersuchen den Einsatz von Robotern in der Pflege vor allem unter dem Kriterium des Wohlergehens älterer pflegebedürftiger Menschen \cite[S. 28]{sharky}. In Bezug auf die unterstützende- oder Pflegeassistenz sehen sie die Gefahr, dass durch diese sich der menschliche Kontakt in ihrem Alltag reduziert, weil einfache Tätigkeiten wie Füttern oder Putzen, die auch ohne Pflegekraft ausgeführt werden können, von Roboter übernommen werden [ebd.: 29]. Hier besteht die Gefahr, dass die Älteren das Gefühl einer Verobjektivierung erfahren, sowie dass sie die Kontrolle über ihr Leben zu verlieren. Die Abnahme sozialer Interaktion im Alltag führt oftmals zu einer Zunahme des Stressempfindens und zur Verringerung kognitiver Fähigkeiten, allgemein zeichnet sie sich durch eine Verschlechterung des psychischen und körperlichen Gesundheit aus [ebd.: 29/30]. Pflegebedürftigen durch das Einführen von Robotern in der Pflege zusätzlich sozialer Interaktion zu entziehen bewerten Sharkey und Sharkey als ethisch nicht vertretbar, wobei sie anmerken, dass Roboter im besten Fall durch Interaktion ihrerseits den Mangel kompensieren \cite[S. 30]{sharky}. Dieses bedarf weiterer Untersuchungen.\\Wenn die Anwendung von Robotern sich als wirtschaftlich erfolgreich herausstellt, besteht die Gefahr, dass sich ihr Einsatz trotz ethischer Unzulänglichkeiten durchsetzt. Gründe dafür können die bereits genannten demographischen Entwicklungen in Industrienationen wie auch die mangelhaften Beschäftigungszahlen im Pflegebereich sein [ebd.: 28 ff].
Problematisch ist, dass der Einsatz von Robotern im Gesundheitsbereich die Bereitstellung von  weiteren Mitteln zur Weiterentwicklung und Erforschung neuer Technologien rechtfertigt \cite[57]{haker}. Haker [ebd.] bemerkt hierzu, dass wenn die Technologien nunmal vorhanden sind, sie dementsprechend auch auf diesen neuen Bereich angewandt werden. Bevor überhaupt ethische Kriterien und Regeln für den Einsatz von Robotern diskutiert und festgelegt werden, wird ihr Einsatz bereits vorangetrieben, da der Stand der Technologie diesen hergibt. Es existiert weltweit im Bereich der Technologieforschung und -entwicklung ein großes Interesse, Roboter kontinuierlich weiterzuentwickeln und im Bereich der Anwendung zu Erproben. Zudem stellt sich die Frage, wer darüber entscheidet, wie die Roboter agieren und wie sie designed \ref{sec:values} sind. "In  Feldern  wie  der  Pflegerobotik,  die  sich  noch  in  einem  sehr  frühen  Stadium  der  Entwicklung  befinden  und  deren  Anwendungsmöglichkeiten  sich  folglich  erst  unscharf  abzeichnen,  ist  diese  […] folgenorientierte  Herangehensweise  mit  grundlegenden Problemen  konfrontiert  –  schließlich  liegen  die  Technikfolgen  noch  weitgehend  im  Dunkeln,  womit  auch  deren  ethische  Beurteilung weitgehend ins Leere läuft (was jedoch im Grunde ein Problem unzureichenden prognostischen Wissens und keines der normativen Bewertung an sich darstellt)” \cite[S. 148]{kehl}.
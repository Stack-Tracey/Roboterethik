%\chapter{Ethische Erläuterungen zu Robotik in der Pflege}
%\label{ch:ethik}
%\section{Transparenz, Big-Data, Privacy, values in Design}
%\label{sec:trans}
%Verschiedene Veröffentlichungen beschäftigen sich in den letzten Jahren mit der Frage, inwiefern der Einsatz von Robotik in der Pflege ethisch vertretbar ist. Haker \cite[S. 56]{haker} nennt drei Bereiche, in denen neue Technologien hilfreich sein können und neuerdings erprobt werden: die Pflegeassistenz, das Monitoring sowie die soziale Förderung. Als Gründe für die Entwicklung von Robotern in der Pflege führt sie den demographischen Wandel in vielen Industrienationen, den Pflegenotstand, die Beförderung von Unabhängigkeit in der häuslichen Pflege durch Monitoring und Überwachung, sowie die Kostenreduzierung an [ebd.: 56].

%\\Auch Sharkey und Sharkey sehen als wichtige Bereiche, in denen Roboter eingesetzt werden können, die Unterstützung der Älteren, sowie der sie pflegenden; das Monitoring von Verhalten und Gesundheitszustand; sowie das Gesellschaftleisten \cite[S. 27]{sharky}. Menschen können durch Roboter emotional stimuliert werden und diese können dabei helfen “Gefühle wie Traurigkeit, Zorn und Einsamkeit zu regulieren” \cite[S. 58]{haker}. Was die ethischen Konsequenzen angeht, stimmen die meisten Veröffentlichungen hinsichtlich der sich ergebenen Problematiken überein, erkennen jedoch auch den Nutzen an. An dieser Stelle wird sich eine Analyse der sozialen Unterstützung durch Roboter beschränkt. Haker stellt drei Modelle vor, in denen sie die unterschiedlichen Argumentationslinien bezüglich der Position von Robotern in sozialen Beziehungen im Pflegebereich darlegt \cite[S. 59 ff]{haker}. Im Ausschlussmodell wird angenommen, dass zwischen Menschen und Robotern keine gleichwertige Beziehung existieren kann. Roboter werden als zu sozialer Interaktion nicht fähig gesehen, problematisch sei es, wenn Pflegebedürftige dieses durch kognitive Einschränkungen nicht mehr nachvollziehen können. “[…]So warnen Kritiker nicht nur vor der Infantilisierung der Klienten, die durch die BetreuerInnen oder Angehörigen erfolgen könnte, sondern zugleich besteht auch die Gefahr der Objektivierung, indem letztlich nämlich mit den Bedürfnissen älterer Menschen gespielt werde. Die absichtliche Simulation reziproker Interaktion durch Dritte ist von einer anderen Kategorie als die selbstbestimmte Entscheidung älterer Menschen, Roboter als soziales Spielzeug in ihr Leben einzubeziehen” [ebd.: 60]. Im Ergänzungsmodell werden Roboter vor allem für gewisse Arbeiten gedacht, die durch eine Ergänzung der Pflegeleistung diese unterstützen. Dabei wird der Einsatz von Robotern immer durch das Pflegepersonal betreut, “[…]ihr Einsatz ist klar durch den therapeutischen Rahmen gegeben, den weder die Klienten (bzw. Patienten) noch die Roboter durchbrechen können oder sollen” [ebd.: 61]. Haker wirft die Frage auf, ob in dieser Argumentationslinie das autonome Handlungsvermögen von Robotern nich unterschätzt wird \cite{haker}.\\ Im Kompensationsmodell geht es darum durch den Einsatz von Robotern die Abwesenheit anderer Interaktion zu kompensieren. Wenn soziale Interaktion mit Angehörigen oder Pflegepersonal zeitlich nicht möglich ist, sei es immer noch besser wenn Roboter den zu Pflegenden ein Wohlgefühl vermitteln und ihnen Gesellschaft leisten würden. Die Argumentationslinie des Kompensationsmodells bewertet das Steigern des Wohlbefindens als wichtiger, selbst wenn die zu Pflegenden bezüglich der Reziprozität der Beziehung getäuscht werden würden, falls sie kognitiv nicht mehr feststellen können, dass sie gerade mit einem Roboter interagieren [ebd.: 62].\\ Je nach dem, welcher Argumentationslinie gefolgt wird, wird die Annahme vertreten, dass soziale Beziehungen zu Robotern niemals gleichwertig sein können, was im schlimmsten Fall von Älteren oder Demenzkranken nicht gemerkt wird, womit sie also getäuscht werden. Oder der Einsatz von Robotern wird dennoch als positiv bewertet, da anderweitige soziale Interaktion bewusst ergänzt werden kann, oder im schlechteren Fall die Abwesenheit sozialer Interaktion durch diese andere Form der Interaktion kompensiert.\\Sparrow und Sparrow lehnen den Einsatz von Robotern nicht grundsätzlich ab, befinden ethische Bedenken jedoch als zentral. Sie weisen darauf hin, wie kompliziert die einzelnen Aufgaben im Bereich der Pflege sind, und bezweifeln, dass künstliche Intelligenz in naher Zukunft solch komplexe und verantwortungsvolle Aufgaben übernehmen werden kann \cite[S.145 ff]{sparrow}. Sparrow und Sparrow gehen davon aus, dass das zentrale menschliche Bedürfnis, geliebt zu sein und umsorgt zu werden, von Robotern nur befriedigt werden kann, wenn man der Täuschung unterliegt, dass diese gleichwertige Kreaturen mit Gefühlen sind \cite[S. 154 ff]{sparrow}. Beim Empfinden dieser positiven Emotionen ist die Beziehung zwischen zwei Lebewesen zentral. Sie ist dadurch charakterisiert, dass auch ein Gegenüber Bedürfnisse und Erwartungen hat, und dass gegenseitige Forderungen die Beziehung formen, welche sowohl unvorhersehbar, als auch manchmal anmaßend und unerwartet sein können [ebd.: 149]. “For robots to be capable even of imitating these responses successfully they would need to possess physical bodies capable of the same level of expressiveness and individuality as human bodies. Moreover, entities which do not understand the facts about human experience and mortality that make tears appropriate will be unable to fulfil this caring role” \cite[S. 154]{sparrow}. Die Täuschung, sich von einem Roboter umsorgt und geliebt zu fühlen, ist vor allem problematisch, da Illusionen wirkliche Bedürfnisse nicht dauerhaft befriedigen, wirkliche Interessen nicht dauerhaft bedienen und auch ein Wohlgefühl nicht dauerhaft illusionär, oder durch Selbsttäuschung, aufrecht erhalten werden kann [ebd.:155]. Menschen wollen nicht in illusionärer Annahme glauben, dass sie von illusionären technischen Maschinen geliebt und umsorgt werden, sondern sie haben das reale Bedürfnis von Menschen geliebt und umsorgt zu werden [ebd.]. “Insofar as robots can make people happier only when they are deceived about the robots’ real nature, robots do not offer real improvements to people’s well-being; in fact the use of robots can be properly said to harm them“ [ebd.].  Auch Haker stellt diesbezüglich fest: “Ohne diese Form der imaginativen Personalisierung des Roboters verlöre das Spiel mit ihm schnell seinen Reiz – oder umgekehrt: es wäre nicht mehr klar, was der Unterschied beispielsweise zu Stofftieren wäre, mit denen ältere Menschen genauso imaginativ soziale Interaktionen aufbauen könnten“ \cite[S. 59]{haker}. Sparrow und Sparrow vermuten, dass positive emotionale Effekte, die aus der Interaktion mit Robotern hervorgehen, sich nicht über einen langen Zeitraum halten lassen, da eine authentische Beziehung nicht aufgebaut werden kann \cite[S. 149]{sparrow}. Diese Effekte beruhen somit bloß auf der Faszination einer neuen, anregenden Erfahrung. Sharkey und Sharkey beantworten die Frage, ob ein Roboter für Ältere ein*e Gefährt*In darstellen kann, mit der Festellung, dass einsame Menschen von der Anwesenheit eines Roboters profitieren können, aber sicherlich um einiges mehr profitieren würden, wenn sie sich in einem freundlichen sozialen Umfeld befänden \cite[S. 34]{sharky}. Sie schreiben jedoch auch, dass Roboter als Gefährten nicht einfach aufgrund der stattfindenden Täuschung als umethisch gewertet werden können. Ältere könnten durchaus bewusst entscheiden, dass sie die Interaktion mit Robotern genießen, auch wenn es sich um eine illusionäre Beziehung handelt [ebd.: 36]. Auch von einer Infantilisierung kann nicht in jedem Fall gesprochen werden, es gibt durchaus Situationen wo ein älterer Mensch sich entscheidet einfach die Möglichkeit zu nutzen und das Beste daraus zu machen.
%Problematisch ist, dass der Einsatz von Robotern im Gesundheitsbereich die Bereitstellung von  weiteren Mitteln zur Weiterentwicklung und Erforschung neuer Technologien rechtfertigt %\cite[S. 57]{haker}. Haker [ebd.] bemerkt hierzu, dass wenn die Technologien nunmal vorhanden sind, sie dementsprechend auch auf diesen neuen Bereich angewandt werden. Bevor überhaupt ethische Kriterien und Regeln für den Einsatz von Robotern diskutiert und festgelegt werden, wird ihr Einsatz bereits vorangetrieben, da der Stand der Technologie diesen hergibt. Es existiert weltweit im Bereich der Technologieforschung und -entwicklung ein großes Interesse, Roboter kontinuierlich weiterzuentwickeln und im Bereich der Anwendung zu Erproben. Zudem stellt sich die Frage, wer darüber entscheidet, wie die Roboter agieren und wie sie designed sind.

%\chapter{Values and Design}

%Nissenbaum (2005) setzt sich mit der Frage auseinander, inwiefern values in design, also die durch das jeweilige Design implizierten Werte, besser in technischen und naturwissenschaftlichen Bereichen reflektiert und integriert werden können. Oftmals gibt es in diesen universitären Fakultäten wenig Überschneidungen mit den Sozial- und Geisteswissenschaften, welche eine längere Tradition der Methodologie aufweisen (ebd.: lxvi). Sie schlägt vor, dass pflichtbewusste Designer*Innen ihre values in design auf drei Wissensebenen reflektieren. Zuerst werden diese hinsichtlich des Wissensstandes in Technik und Naturwissenschaft überprüft, folgend durch eine philosophische Reflexion, und zuletzt durch eine empirische Überprüfung im Anwendungsfeld (ebd.). Durchgängig sollte dabei im Fokus stehen, dass sich alle drei Bereiche durchdringen und gegenseitig beeinflussen. Sie sollten also, während der Fokus sich in einem dieser Bereiche befindet, kontinuierlich mitgedacht werden. Während also im ersten Schritt sämtliche im jeweiligen technischen Feld vorhandenen Werte auf den Prüfstand gestellt werden um sich sinnvoll für ein Design zu entscheiden, wird im zweiten Schritt geschaut, wo Werte ihren Ursprung haben, welche Relevanzen und Bedeutungen ihnen innewohnen und wie sie normativ beeinflusst sind (ebd.: lxvii). Werte können eine moralische, eine politische und eine soziale Konnotation haben (ebd.). Werden Werte ins Design bewusst integriert, sollte im nächsten Schritt überprüft werden, ob ihre Einverleibung geglückt ist, also ob die Intentionen der*s Designer*In sich erfüllen (ebd.; lxviii).  Möglich ist, ein partizipatives Design zu erstellen, wo die Entwicklungsschritte einer Technologie oder einer Maschine jeweils rückgekoppelt sind an eine Überprüfung auf ihre Wirksamkeit im späteren Anwendungsbereich (ebd.). Nissenbaum (2005) hat mit Kolleg*Innen hierfür eine eigene Methode entwickelt, in der hierfür vier Schritte durchlaufen werden. Zunächst die Entdeckung der jeweils zugrunde liegenden Werte, folgend ihre Übersetzung in das jeweilige Feld, danach die Lösung zumeist auftretender Konflikte oder Inkontinenzen und zuletzt die Überprüfung einer erfolgreichen Einverleibung (ebd.: lxix).

%\section{Datenschutz}
%Der Einsatz von Robotern in der Pflege allgemein, aber auch in Bezug auf soziale Interaktion, birgt viele Möglichkeiten, über eine reflektierte Herangehensweise bezüglich der values in design, die ethischen Vorraussetzungen positiv zu beeinflussen. Wie Sharkey und Sharkey (2010) und Kehl (2018) feststellen, bedarf es hier einer genauen Überprüfung der Grundvorraussetzungen und eine Zusammenarbeit mit den Pflegebedürftigen. Mithilfe empirischer Untersuchungen und  partizipativer Technikgestaltung wäre es möglich, wichtige Werte von Älteren herauszufinden und aufzugreifen und somit auf technischer Seite dafür zu sorgen, dass ethische Fragen in das Design eingearbeitet werden. In der Literatur angesprochene Themen sind dabei, wie eine Kameraüberwachung in das Aussehen und Auftreten von Robotern integriert werden kann oder unter welchen Voraussetzungen gewisse private Räumen wie Bad und Schlafzimmer von Robotern betreten werden dürfen. Das Aussehen von Robotern ist eine weitere wichtige Frage, werden diese eher dem Aussehen von Lebewesen nachempfunden, oder wird ein abstraktes Äußeres bevorzugt. Je abstrakter die Erscheinung eines Roboters ausfällt, desto eher lässt sich vermuten, dass Pflegebedürftiger einer Täuschung weniger schnell unterliegen. Es wäre möglich den Roboter so zu kreieren, dass einer Vereinsamung von Pflegebedürftigen durch Warnmechanismen entgegengewirkt wird. 
%(Anknüpfungspunkt values in design) \todo{Hier den Teil zu values and design rein}Werden diese im Hinblick darauf entwickelt, um Pflegebedürftigen zu helfen, oder im Hinblick darauf, Kosten im Pflegebereich einzusparen und das Arbeitspensum des Pflegepersonals zu reduzieren \cite[S. 30]{sharky}.

%\section{Bedenken beim Einsatz von Pflegerobotern}
%Wenn die Anwendung von Robotern sich als wirtschaftlich erfolgreich herausstellt, besteht die Gefahr, dass sich ihr Einsatz trotz ethischer Unzulänglichkeiten durchsetzt. Gründe dafür können die bereits genannten demographischen Entwicklungen in Industrienationen wie auch die mangelhaften Beschäftigungszahlen im Pflegebereich sein [ebd.: 28 ff].

%Sharkey und Sharkey untersuchen den Einsatz von Robotern in der Pflege vor allem unter dem Kriterium des Wohlergehens älterer pflegebedürftiger Menschen \cite[S. 28]{sharky}. In Bezug auf die unterstützende- oder Pflegeassistenz sehen sie die Gefahr, dass durch diese sich der menschliche Kontakt in ihrem Alltag reduziert, weil einfache Tätigkeiten wie Füttern oder Putzen, die auch ohne Pflegekraft ausgeführt werden können, von Roboter übernommen werden [ebd.: 29]. Hier besteht die Gefahr, dass die Älteren das Gefühl einer Verobjektivierung erfahren, sowie dass sie die Kontrolle über ihr Leben zu verlieren. Die Abnahme sozialer Interaktion im Alltag führt oftmals zu einer Zunahme des Stressempfindens und zur Verringerung kognitiver Fähigkeiten, allgemein zeichnet sie sich durch eine Verschlechterung des psychischen und körperlichen Gesundheit aus [ebd.: 29/30]. Pflegebedürftigen durch das Einführen von Robotern in der Pflege zusätzlich sozialer Interaktion zu entziehen bewerten Sharkey und Sharkey als ethisch nicht vertretbar, wobei sie anmerken, dass Roboter im besten Fall durch Interaktion ihrerseits den Mangel kompensieren \cite[S. 30]{sharky}. Dieses bedarf weiterer Untersuchungen. Roboter in der Pflege können  positive Effekte haben, sollten sie die Abhängigkeit vom Pflegepersonal reduzieren und eine längere Selbstständigkeit im eigenen Zuhause ermöglichen [ebd.: 31].  (Siehe conclusion Sharkey2 für Regeln) \todo{sharkey anschauen}
%In ihrem Fazit bezieht Haker drei unterschiedliche ethische Rahmentheorien mit ein, um mit Hilfe dieser und der zuvor genannten Argumentationslinien Regeln für den Einsatz von Robotern in der Pflege zu erarbeiten \cite{haker}.( Regeln im Schlussteil?)\todo{schlussteil?} “Eine Ethik, die sich auf die Rahmentheorie der Menschenrechte stützt, muss klären, wie sich der Einsatz von Robotern zum Recht auf Wohlergehen, auf Privatheit, auf Gewaltfreiheit und insgesamt auf den Schutz der persönlichen Integrität verhält “ [ebd.: 63/64]. Innerhalb einer solchen Ethik stellt sich grundsätzlich die Frage, ob der Einsatz von Robotern nicht die Würde älterer Menschen verletzt. Wird im Sinne eine Befähigungsethik im Hinblick auf die Steigerung des Wohlbefinden argumentiert, stellt sich die zentrale Frage “unter welchen Bedingungen Roboter Menschen nicht nur stimulieren, sondern tatsächlich in ihren Fähigkeiten fördern und zu mehr Freiheit ermächtigen” [ebd.: 64]. Auch eine utilitaristische ethische Ausrichtung betrachtet eine Steigerung des Wohlbefindens \cite[S.8]{mill}, und somit die Effekte der Interaktion zwischen Mensch und Roboter. Diese würde allerdings argumentativ so weit gehen, dass die positiven Effekte wichtiger sind, als die menschliche Würde, sollten Menschen nicht mehr in der Lage sein eine Verletzung ihrer Würde zu reflektieren \cite[S. 64]{haker}.\\Kehl spricht sich für eine umfassende Auseinandersetzung mit der Frage, inwiefern der Einsatz von Robotik in der Pflege sinnvoll sein kann, aus \cite[S. 143 ff]{kehl}. “Für  die  Pflegerobotik  erscheint  dies  besonders  drängend, da man es hierbei mit einer Technologie zu tun hat, die aufgrund ihrer Interaktivität  und  zunehmenden  Autonomiefähigkeit  ganz  neue  technische  Möglichkeiten  bietet,  die  aber  gerade  nicht  Selbstzweck  sein  dürfen,  sondern  die  es  sinnvoll  –  und  zwar  im  Sinne  guter  Pflege  –  nutzbar  zu  machen  gilt” [ebd. 144]. Als Instrument schlägt er die Bedürfnis- und Bedarfsanalyse vor.
Sowohl was das Thema Transparenz angeht, als auch Values in Design, ist es notwendig bei der Entwicklung neuer Technologien in einen kontinuierlichen Austausch mit denjenigen zu treten, die vom Einsatz dieser Technologien letztlich betroffen sind. Dies kann einerseits die Akzeptanz fördern, andererseits das Anwendungsspektrum verbessern und die Wirkmächtigkeit verbessern.
Bei der interdisziplinären Bedarfserhebung geht es darum, “ein  genaues  Verständnis  für  die  tatsächlichen  (und  nicht  nur  unterstellten)  Lebens-  und  Problemlagen  der  potenziellen  Nutzer  zu  entwickeln” [ebd.]. Hierauf folgt eine partizipative Technikgestaltung, welche die Technikanwendung in Hinblick auf die Zielgruppe Nutzer*Innenfreundlich gestaltet.

%"In  Feldern  wie  der  Pflegerobotik,  die  sich  noch  in  einem  sehr  frühen  Stadium  der  Entwicklung  befinden  und  deren  Anwendungsmöglichkeiten  sich  folglich  erst  unscharf  abzeichnen,  ist  diese  […] folgenorientierte  Herangehensweise  mit  grundlegenden Problemen  konfrontiert  –  schließlich  liegen  die  Technikfolgen  noch  weitgehend  im  Dunkeln,  womit  auch  deren  ethische  Beurteilung weitgehend ins Leere läuft (was jedoch im Grunde ein Problem unzureichenden prognostischen Wissens und keines der normativen Bewertung an sich darstellt)”. (Kehl 2018: 148) \cite[S. 148]{kehl} \\\\\\\



Allerdings  hat  die  Ethik  aus  
148C. Kehlverschiedenen  Gründen  Mühe,  in  Problemkonstellationen,  wie  sie  sich  aktuell  im  Bereich der Pflegerobotik abzeichnen, dieser Aufgabe gerecht zu werden:1.Unsicherheit  der  Folgenabschätzung:  Quelle  normativer  Unsicherheiten  und  mithin  Gegenstand der ethischen Bewertung ist in der Regel nicht die Technik an sich, sondern deren  Rolle  in  konkreten  soziotechnischen  Handlungszusammenhängen  (Grunwald  2013a, S.4). Dazu gehören wesentlich die intendierten sowie nicht intendierten Folgen, die  mit  einem  Technikeinsatz  verbunden  sind  und  deren  moralische  Implikationen  es  ethisch  zu  klären  gilt.  In  Feldern  wie  der  Pflegerobotik,  die  sich  noch  in  einem  sehr  frühen  Stadium  der  Entwicklung  befinden  und  deren  Anwendungsmöglichkeiten  sich  folglich  erst  unscharf  abzeichnen,  ist  diese  konsequenzialistische  (folgenorientierte)  Herangehensweise  mit  grundlegenden 



VALUES IN DESIGN!!!

\chapter{Fazit}
\label{ch:fazit}

In ihrem Fazit bezieht Haker drei unterschiedliche ethische Rahmentheorien mit ein, um mit Hilfe dieser und der zuvor genannten Argumentationslinien Regeln für den Einsatz von Robotern in der Pflege zu erarbeiten \cite{haker}. “Eine Ethik, die sich auf die Rahmentheorie der Menschenrechte stützt, muss klären, wie sich der Einsatz von Robotern zum Recht auf Wohlergehen, auf Privatheit, auf Gewaltfreiheit und insgesamt auf den Schutz der persönlichen Integrität verhält “ [ebd.: 63/64]. Innerhalb einer solchen Ethik stellt sich grundsätzlich die Frage, ob der Einsatz von Robotern nicht die Würde älterer Menschen verletzt. Wird im Sinne eine Befähigungsethik im Hinblick auf die Steigerung des Wohlbefinden argumentiert, stellt sich die zentrale Frage “unter welchen Bedingungen Roboter Menschen nicht nur stimulieren, sondern tatsächlich in ihren Fähigkeiten fördern und zu mehr Freiheit ermächtigen” [ebd.: 64]. Auch eine utilitaristische ethische Ausrichtung betrachtet eine Steigerung des Wohlbefindens \cite[8]{mill}, und somit die Effekte der Interaktion zwischen Mensch und Roboter. Diese würde allerdings argumentativ so weit gehen, dass die positiven Effekte wichtiger sind, als die menschliche Würde, sollten Menschen nicht mehr in der Lage sein eine Verletzung ihrer Würde zu reflektieren \cite[64]{haker}. Kehl spricht sich für eine umfassende Auseinandersetzung mit der Frage, inwiefern der Einsatz von Robotik in der Pflege sinnvoll sein kann, aus \cite[143 ff]{kehl}. \“Für  die  Pflegerobotik  erscheint  dies  besonders  drängend, da man es hierbei mit einer Technologie zu tun hat, die aufgrund ihrer Interaktivität  und  zunehmenden  Autonomiefähigkeit  ganz  neue  technische  Möglichkeiten  bietet,  die  aber  gerade  nicht  Selbstzweck  sein  dürfen,  sondern  die  es  sinnvoll  –  und  zwar  im  Sinne  guter  Pflege  –  nutzbar  zu  machen  gilt” [ebd. 144]. Als Instrument schlägt er die Bedürfnis- und Bedarfsanalyse vor. Sowohl was das Thema Privatsphäre angeht, als auch values in design, ist es notwendig bei der Entwicklung neuer Technologien in einen kontinuierlichen Austausch mit denjenigen zu treten, die vom Einsatz dieser Technologien letztlich betroffen sind [ebd.:].% Dies kann einerseits die Akzeptanz fördern, andererseits das Anwendungsspektrum verbessern und die Wirkmächtigkeit verbessern. Bei der interdisziplinären Bedarfserhebung geht es darum, “ein  genaues  Verständnis  für  die  tatsächlichen Lebens-  und  Problemlagen  der  potenziellen  Nutzer  zu  entwickeln” [ebd.]. Hierauf folgt eine partizipative Technikgestaltung, welche die Technikanwendung in Hinblick auf die Zielgruppe Nutzer*Innenfreundlich gestaltet.
Häufig  wird  der  Kritikpunkt  vorgebracht,  dass  Roboter  keine  echte  Zuwendung  ersetzen  können.  Es wurde festgestellt,  dass  Roboter  zwar  zur  Stimmungs-aufhellung   von   Demenzpatienten   beitragen   können,   aber   nicht   die   Wirkung   von   zwischenmenschlichen  Kontakten  erzielen \cite[79]{vier}. Es könnte eine Abnahme sozialer Interaktion stattfinden, Pflegebedürftige könnten zunehmend vernachlässigt werden, wobei die Vernachlässigung möglicherweise damit entschuldigt wird, dass Roboter emotionale und körperliche Bedürfnisse bedienen. Es gibt aber auch Evidenz  für  den  therapeutischen  Nutzen  von  simulierten  sozialen  Stimuli. Demenzkranke Patienten könnten so vom Roboter angeregt werden, mit ihrem sozialen Umfeld zu interagieren \cite[79]{vier}. Wenn ein Roboter primär eingesetzt wird, um Gesellschaft zu leisten, wäre es möglich, dass er registriert, wieviel Zeit Pflegebedürftige ohne soziale Interaktion verbracht haben. Die Roboter könnten eine Warnung abgeben, wenn die Pflegebedürftigen zu lange Zeiträume allein verbracht haben. Roboter in der Pflege können  positive Effekte haben, sollten sie die Abhängigkeit vom Pflegepersonal reduzieren und eine längere Selbstständigkeit im eigenen Zuhause ermöglichen \cite[31]{sharky}. Dem zufolge kann der Einsatz von Robotern in der Pflege zwar zu einem Zeitgewinn führen, es  besteht  jedoch  die  akute  Gefahr,  dass  die  gewonnenen  Minuten  aus  ökonomischen  Gründen nicht  dem  einzelnen  Zentrumsbewohner  zugutekommen.  Vielmehr  dürfte  der  Robotereinsatz  dazu  führen,  dass  eine  höhere  Anzahl  an  Patienten  von  der  gleichen  Anzahl an Pflegekräften oder dieselbe Anzahl an Patienten von einer geringeren Anzahl an  Pflegekräften  betreut  wird\cite[143]{sparrow}. Die in Sektion \ref{sec:priv} dargelegten Erläuterungen könnten einen Verlust von Privatsphäre und Einschränkung der persönlichen Freiheit bedeuten.
Täuschung und Infantilisierung könnten vorkommen, wenn Pflegebedürftige dazu angeregt werden mit Robotern eine gleichwertige Beziehung aufzubauen Wenn die Kontrolle über in der Hand der Pflegebedürftigen liegt, sind, sollte etwas schief gehen, die Verantwortlichkeiten unklar.





%Im Gegensatz zu Computer Ethics allgemein, wirft der Einsatz von Robotern weitergehende Fragen auf. Roboter sind mobil und können Individuen verfolgen. Sie verkörpern in ihrem Äußeren Lebewesen. Ihre Erscheinungsform kann dazu führen, dass sie auch in Bereichen akzeptiert werden, in denen Videoüberwachung unter anderen Bedingungen nicht vorstellbar wäre (siehe \ref{sec:values}. Ihre den Lebewesen nachempfundene Erscheinungsform kann zudem bewirken, dass den Robotern soziale Fähigkeiten zugetraut werden, welche sie nicht besitzen.


Ein Bereich, der durch Richtlinien von Sharkey und Sharkey geregelt werden könnte, ist die Zeitdauer, die Pflegebedürftige allein, nur in Begleitung eines Roboters zurückgelassen werden dürfen \cite[38]{sharky}. Es könnte eine Vorschrift geben, dass jeder Roboter erst fragen muss, ob körperlicher Kontakt akzeptiert wird, bevor ein Roboter einen Menschen stützt oder anhebt.
Weitere Richtlinien sollten durch umfassende Auswertungen der Auswirkungen eines Robotereinsatzes auf Pflegebedürftige erstellt werden.











   


REGELN!!!!!

%Regeln (Haker 2014: 65/66)
%• Jedem Menschen steht es frei, sich einen „sozialen Roboter“ zuzulegen – dies gilt auch für Menschen im Alter. Sofern sie diese kontrollieren können, spricht nichts gegen die spielerische, imaginative Interaktion von Menschen und (sozialen) Robotern. 
%• Falls in Betreuungskonstellationen Interaktionen zwischen Klienten/Patienten und BetreuerInnen bzw. Mensch-Tier-Interaktionen zeitlich und räumlich möglich sind, diese aber Gefahr laufen, durch den Einsatz von Robotern reduziert zu werden, ist den spontanen reziproken Interaktionen der Vorzug zu geben. Eine Ergänzung bzw. das Spiel mit sozialen Robotern muss daher notwendig in die allgemeinen (menschlichen) Interaktionen integriert werden. 
Ein infantilisierender Einsatz von Robotern ist auszuschließen. Sofern ältere Menschen dazu in der Lage sind, müssen sie über die Funktionsweise von Robotern informiert werden. Sofern sie dazu nicht in der Lage sind, müssen Dritte darin geschult werden, Roboter ergänzend und nicht kompensativ einzusetzen. Dies erfordert eine situations- und kontextabhängige Schulung.  
Sofern Roboter Handlungen ausführen, die bestimmte Reaktionen hervorrufen, ist die Intimität und Integrität der Personen zu gewährleisten. Bewusste Täuschungen sind auszuschließen, was durch Informationen und Kommunikation sowie über die Integration der Roboter in die sozialtherapeutische Begleitung zu gewährleisten ist.  
Roboter können unter Umständen ein Sicherheitsrisiko darstellen. Die Verantwortung für ihren Einsatz ist zu klären, insbesondere dann, wenn sie in Abwesenheit von Betreuungspersonen eingesetzt werden.  

